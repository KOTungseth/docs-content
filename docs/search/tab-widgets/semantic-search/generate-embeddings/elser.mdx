


This is how an ingest pipeline that uses the ELSER model is created:

```console
PUT _ingest/pipeline/my-text-embeddings-pipeline 
{ 
  "description": "Text embedding pipeline",
  "processors": [ 
    { 
      "inference": { 
        "model_id": ".elser_model_2", 
        "input_output": [
          { 
            "input_field": "my_text_field", 
            "output_field": "my_tokens" 
          } 
        ] 
      } 
    } 
  ] 
}
```

To ingest data through the pipeline to generate tokens with ELSER, refer to the 
<DocLink id="serverlessElasticsearchSemanticSearchElser" section="ingest-the-data-through-the-((infer))-ingest-pipeline">Ingest the data through the ((infer)) ingest pipeline</DocLink> section of the tutorial. After you successfully 
ingested documents by using the pipeline, your index will contain the tokens 
generated by ELSER.
